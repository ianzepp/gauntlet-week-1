# =============================================================================
# Core Server
# =============================================================================
# Bind address/port for the HTTP + WebSocket server.
HOST=0.0.0.0
PORT=3000

# =============================================================================
# Database
# =============================================================================
# Postgres connection string used at startup and for all persistence.
DATABASE_URL=postgres://user:pass@localhost:5432/collaboard
# SQLx pool size. Increase if DB waits become a bottleneck.
DB_MAX_CONNECTIONS=5

# =============================================================================
# LLM (Optional: if unset/misconfigured, AI features are disabled)
# =============================================================================
# Choose provider: anthropic or openai.
LLM_PROVIDER=anthropic
# Provider model name (examples: claude-sonnet-4-20250514, gpt-4o).
LLM_MODEL=claude-sonnet-4-20250514
# Name of the env var that contains the actual API key.
# Example: LLM_API_KEY_ENV=ANTHROPIC_API_KEY or LLM_API_KEY_ENV=OPENAI_API_KEY
LLM_API_KEY_ENV=ANTHROPIC_API_KEY
# Actual provider key env vars (set the one referenced by LLM_API_KEY_ENV).
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
# OpenAI-specific options (used when LLM_PROVIDER=openai).
LLM_OPENAI_MODE=responses
LLM_OPENAI_BASE_URL=https://api.openai.com/v1
# Upstream LLM HTTP timeouts (seconds).
LLM_REQUEST_TIMEOUT_SECS=120
LLM_CONNECT_TIMEOUT_SECS=10

# =============================================================================
# Realtime + AI Limits
# =============================================================================
# Per-client outgoing websocket queue capacity. Increase for bursty fanout.
WS_CLIENT_CHANNEL_CAPACITY=256
# Dirty object flush cadence in ms (in-memory board state -> Postgres).
OBJECT_FLUSH_INTERVAL_MS=100
# AI execution guardrails per prompt.
AI_MAX_TOOL_ITERATIONS=10
AI_MAX_TOKENS=4096

# AI request/token rate limits.
RATE_LIMIT_PER_CLIENT=10
RATE_LIMIT_PER_CLIENT_WINDOW_SECS=60
RATE_LIMIT_GLOBAL=20
RATE_LIMIT_GLOBAL_WINDOW_SECS=60
RATE_LIMIT_TOKEN_BUDGET=50000
RATE_LIMIT_TOKEN_WINDOW_SECS=3600

# =============================================================================
# Frame Persistence Worker
# =============================================================================
# Bounded async queue for frame writes (higher = more burst tolerance, more memory).
FRAME_PERSIST_QUEUE_CAPACITY=8192
# Frames per DB transaction (higher = fewer writes, more persistence lag).
FRAME_PERSIST_BATCH_SIZE=128
# Flush interval in ms (lower = lower lag, more DB write frequency).
FRAME_PERSIST_FLUSH_MS=5
# Retry count for failed batch writes (kept low to avoid queue buildup).
FRAME_PERSIST_RETRIES=2
# Retry backoff base in ms (delay = attempt * this value).
FRAME_PERSIST_RETRY_BASE_MS=20

# =============================================================================
# GitHub OAuth (Required for authentication endpoints)
# =============================================================================
# Create an OAuth App at https://github.com/settings/developers
# Set callback URL to match GITHUB_REDIRECT_URI below.
GITHUB_CLIENT_ID=your-client-id
GITHUB_CLIENT_SECRET=your-client-secret
GITHUB_REDIRECT_URI=http://localhost:5173/auth/github/callback
